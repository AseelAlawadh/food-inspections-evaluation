---
title: "Forecasting restaurants with critical violations in Chicago"
author: "City of Chicago"
date: "December 13, 2014"
output:
  html_document:
    css: assets/journal-chicago/css/journal-chicago.css
    number_sections: yes
  pdf_document:
    number_sections: yes
  word_document: default
---


```{r initialize, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
##==============================================================================
## INITIALIZE
##==============================================================================
## Remove all objects; perform garbage collection
rm(list=ls())
gc(reset=TRUE)
## Check for dependencies
if(!"geneorama" %in% rownames(installed.packages())){
    if(!"devtools" %in% rownames(installed.packages())){
        install.packages('devtools')}
    devtools::install_github('geneorama/geneorama')}
## Load libraries
geneorama::detach_nonstandard_packages()
geneorama::loadinstall_libraries(c("data.table", "ggplot2", "knitr", "glmnet"))
geneorama::set_project_dir("food-inspections-evaluation")
geneorama::sourceDir("CODE/functions/")
library(RSocrata)
library(scales)

## Globally turn off "fixing" indenting for code chunks
opts_chunk$set(tidy = FALSE)

## Set figure output
opts_knit$set(fig.path = "assets/figure")

## Navigate to the top level directory 
geneorama::set_project_dir("food-inspections-evaluation")
```
```{r define_global_variables, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
##==============================================================================
## DEFINE GLOBAL VARIABLES / MANUAL CODE
##==============================================================================
## Select data version
DataDir <- "DATA/20141110"
```
```{r prepare_for_model, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
##==============================================================================
## LOAD CACHED RDS FILES AND MODIFY DATA FOR MODEL
##==============================================================================
dat <- readRDS(file.path(DataDir, "dat_with_inspector.Rds"))
## Remove NA's
dat[,.N,is.na(heat_burglary)]
dat <- dat[!is.na(heat_burglary)]
## Add criticalFound variable to dat:
dat[ , criticalFound := pmin(1, criticalCount)]
## Set the key for dat
setkey(dat, Inspection_ID)
## Match time period of original results
# dat <- dat[Inspection_Date < "2013-09-01" | Inspection_Date > "2014-07-01"]
dat[, .N, Results]
## Remove records where an inspection didn't happen
dat <- dat[!Results %in% c('Out of Business','Business Not Located','No Entry')]
```
```{r create_model_data, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
##==============================================================================
## CREATE MODEL DATA
##==============================================================================
xmat <- dat[ , list(criticalFound,
                    Inspector_Assigned,
                    pastSerious = pmin(pastSerious, 1),
                    ageAtInspection = ifelse(ageAtInspection > 4, 1L, 0L),
                    pastCritical = pmin(pastCritical, 1),
                    consumption_on_premises_incidental_activity,
                    tobacco_retail_over_counter,
                    temperatureMax,
                    heat_burglary = pmin(heat_burglary, 70),
                    heat_sanitation = pmin(heat_sanitation, 70),
                    heat_garbage = pmin(heat_garbage, 50),
                    # risk = as.factor(Risk),
                    # facility_type = as.factor(Facility_Type),
                    timeSinceLast),
            keyby = Inspection_ID]
mm <- model.matrix(criticalFound ~ . -1, data=xmat[ , -1, with=F])
mm <- as.data.table(mm)
```
```{r create_test-train_partitions, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
##==============================================================================
## CREATE TEST / TRAIN PARTITIONS
##==============================================================================
iiTrain <- dat[ , which(Inspection_Date < "2014-07-01")]
iiTest <- dat[ , which(Inspection_Date > "2014-07-01")]
```
```{r glmnet_model, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
##==============================================================================
## GLMNET MODEL
##==============================================================================
# fit ridge regression, alpha = 0, only inspector coefficients penalized
pen <- ifelse(grepl("^Inspector.Assigned", colnames(mm)), 1, 0)
model <- glmnet(x = as.matrix(mm[iiTrain]),
                y = xmat[iiTrain,  criticalFound],
                family = "binomial", alpha = 0, penalty.factor = pen)
w.lam <- 100
lam <- model$lambda[w.lam]
coef <- model$beta[,w.lam]
coefInsp <- coef[grepl("^Inspector.Assigned",names(coef))]
coefInsp <- coefInsp[order(-coefInsp)]
coefNonInsp <- coef[!grepl("^Inspector.Assigned",names(coef))]

## ATTACH PREDICTIONS TO DAT
dat$glm_pred <- predict(model, newx=as.matrix(mm), s=lam, type="response")[,1]
```
```{r prepare_data_for_evaluation_summary, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
# ## Subset test period
datTest <- dat[iiTest]

## Identify the ACTUAL first and second periods
datTest[ , period := ifelse(Inspection_Date < median(Inspection_Date), 1, 2)]
datTest[, .N, keyby=list(period)]
## Identify top half of scores (which *would have* been the first period)
datTest[ , period_modeled := ifelse(glm_pred > median(glm_pred), 1, 2)]
datTest[, .N, keyby=list(period_modeled)]

## Total of inspections / critical found for ACTUAL data
datTest[, list(.N, Violations = sum(criticalFound)), keyby=list(period)]

## Total of inspections / critical found for MODELED scenario
datTest[, list(.N, Violations = sum(criticalFound)), keyby=list(period_modeled)]

## Another way to say "how many would you have found  in the first period"
datTest[period == 1, sum(criticalFound)]
datTest[period_modeled == 1, sum(criticalFound)]
```
```{r prepare_summary_of_results, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
##==============================================================================
## CALCULATE DATA FOR summary_of_results_table
##==============================================================================

## Total of inspections / critical found for ACTUAL data
baseline <- datTest[, list(.N, Violations = sum(criticalFound)), keyby=list(period)]

## Total of inspections / critical found for MODELED scenario
data_driven <- datTest[, list(.N, Violations = sum(criticalFound)), keyby=list(period_modeled)]

summary_of_eval_results_table <- data.frame(baseline$period, baseline$N, baseline$Violations, data_driven$Violations)
names(summary_of_eval_results_table) <- c("Period", "Number of Inspections", "Baseline Violations", "Data-driven Violations")
```

> The Chicago Department of Public Health (CDPH) inspects more than 15,000 restaurants with fewer than three dozen inspectors over the course of the year. This paper develops a predictive model design to identify the likelihood any restaurant that contains critical violations. Since CDPH is obligated to inspect every food establishment, the goal of the model is to identify the riskiest restaurants earlier, thereby reducing the length of exposure of risky restaurants to patrons. In testing, the predictive model was able to identify 23 percent more violations than current operations.

# Introduction

The Chicago Department of Public Health inspects more than 15,000 restaurants with fewer than three dozen inspectors. City of Chicago ordinance requires that most of these establishments must be inspected at least once a year. The task to inspect each restaurant, while also performing other inspections, is completed over the year. 

CDPH conducts three different types of inspections. First, CDPH conducts license inspections for any new establishment with a food license prior to the establishment opening. Each establishment must pass this initial inspection before it is allowed to serve food to patrons. Second, CDPH will conduct canvas inspections; periodic inspections to check the quality of sanitary conditions. The number and frequency of inspections is driven by the type of facility and how it prepares food, inspecting the riskiest restaurants at least two times a year. Finally, CDPH will also respond to complaints submitted to the department. At times, CDPH will reinspect restaurants if the establishment fails or requires reinspections as a result of the previous inspection. Often, these reinspections are completed within a week of the initial inspection.

License inspections are coordinated with Business Affairs and Consumer Protection, who grants food establishment licenses to new establishments. The quantity and location of these inspections is driven by license applications, thereby, dependent on the economy, entrepreneurship, and other outside factors beyond the control of the City. Despite their routine nature, these inspections can be characterized as routine, but not a guarantee to pass. Frequently, establishments fail these initial inspections because they have not yet turned-on a refrigerator or connected fundamental pumbing. Under these circumstances, CDPH will re-inspect those establishments to ensure those conditions are passed before they are allowed to open.

CDPH registers complaints from residents, alderman, and referrals from hospitals. Often, these requests are driven through the City of Chicago's 311 system, which can be submitted through residents calling 311 or submitting a request through an online form. Uniquely, CDPH also encourages submissions through the [Foodborne Chicago](http://www.cdc.gov/mmwr/preview/mmwrhtml/mm6332a1.htm) program. [Machine learning algorithms](https://github.com/smartchicago/foodborne) scans Twitter for individuals complaining or indicating potential food poisioning cases. These tweets are identified and a human will contact the user, providing a link and information on how they can [report their complaint](https://www.foodbornechicago.org/) to CDPH.

The Foodborne program and 311 system has assisted CDPH in targeting and identifying complaint-driven requests. Yet, the department has a sizeable task to complete canvas inspections. Canvas inspections occur throughout the year and are somewhat random inspections of various restaurants. The work is organized by CDPH-defined "risk levels", which are divided into three categories: risk 1 (highest), risk 2, and risk 3.

The risk level is determined by food handling practices required for each establishment. Restaurants and other establishments that directly handle ingredients and prepare food, such as needs to cool or heat food, are generally categorized as risk 1. The lowest risk generally consists of prepackages and non-perishable food. Risk level also drives frequency of inspection. Risk 1 facilities are inspected more frequently, with a target of at least twice a year; risk 2 are inspected at least once a year; and risk 3 is inspected once every other year.

Risk levels do help prioritize inspections to focus on establishments with the highest likelihood of spreading food born illnesses. However, `r percent(table(dat$Risk)[1]/sum(table(dat$Risk)))` of those establishments in our dataset are categorized as risk 1. The high proportion of risk 1 establishments means there is still a substantial queue to be inspected. Yet, the work is certainly achievable. Assuming 32 inspectors, each inspector would need to complete `r format(round(table(dat$Risk)[1]/32/230, 0), nsmall=0)` canvass inspections each year---in addition to complaint and new license inspections.

There are 42 different possible violations that can be cited by CDPH. Often, these violations are classified into three categories: critical, serious, and minor violations. Critical violations consist of 9 different violations that are most likely to create conditions for food born illnesses, such as failure to heat food to proper temperatures or to keep items properly fridgerated at the proper temperatures. Conversely, minor violations can be as simple as leaving a rag in the sink. Restaurants can fail their inspections with as little as one critical violation. Several serious and minor violations during an inspection can also lead to a failed outcome.

This paper formulates a model to derive the likelihood for each establishment to have critical violations. This model can be used to prioritize which restaurants should be inspected first. By targeting the highest-probability restaurants, CDPH can minimize the amount of exposure restaurant patrons have to the unsanitary conditions that are most likely to lead to food born illnesses. This paper will focus on prioritizing inspections of risk 1 and risk 2 restaurants, since these must be inspected at least once a year.

# Data

The City of Chicago publishes over 600 datasets on the [open data portal](https://data.cityofchicago.org), including the results of food inspections from 2011 to present. The [food inspection dataset](https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5) includes the name of the establishment, address, risk level, inspection date, results, and a detailed list of violations found during the inspection.

At this time, the food inspection database is not hosted by the City of Chicago, instead, a file of all food inspections are sent to the City of Chicago open data team on a daily basis, which is automatically uploaded to the portal every morning. Thus, the rawest form of data available to the research team was the data available on the open data portal.

In addition, the City also publishes other relevant data on the portal, including:

* Business licenses from 2011 to present
* Detailed crime data from 2001 to present
* Various 311 data, including garbage and sanitation complaints

## Combining Data

# Model Development

The principle question is whether we can reasonably determine the probability that a restaurant inspection will yield at least one critical violation. That is, the focus will be whether or not any critical violation is found---a binary response. We use a glmnet model to estimate the impact of 

While the following form can be expressed a number of ways, the logistic form is commonly expressed as the "log-odds transformation". 

$$
\begin{aligned}
\log = \frac{\text{Pr}(V=1|X=x)}{\text{Pr}(V=0|X=x)} = \beta_0 + \beta^T x
\end{aligned}
$$

Thus, the objective function is to minimize 

$$
\begin{aligned}
\min_{(\beta_0, \beta) \in \mathbb{R}^{p+1}} -\left[\frac{1}{N} \sum_{i=1}^N y_i \cdot (\beta_0 + x_i^T \beta) - \log (1+e^{(\beta_0+x_i^T \beta)})\right] + \lambda \big[ (1-\alpha)||\beta||_2^2/2 + \alpha||\beta||_1\big]
\end{aligned}
$$

A review of the methods to find this solution is provided by Friedman, Trevor, and Tibshirani (2010), whose glmnet library for R was used to provide estimates.

## Significant Variables 

The regression analysis shows the inspectors have a significant impact of the rate of finding critical violations. To provide anonymity, inspectors were grouped by similar performance estimated by individual regression coefficients. 

Whether the restaurant had a critical violation in the past was a positive perdictor of future critical violations.  Likewise, historical serious violations was also a predictor of future performance. In effect, past performance perdicted future outcomes, with those with critical violations more likely to repeat those violations than even those with, at most, serious violations.

The elapsed time since the last violation also increased the likelihood that inspectors found critical violations. However, restaurants probability of having critical violations fell over the lifespan of the restaurant. As restaurants grow older, they are less likely to have critical violations while long time-periods between inspections increased the likelihood.

Characteristics besides the restaurant itself were also indicators of future performance. Trends in weather, nearby reports of burglary, and complaints about sanitation and garbage seems to explain increases. An increase in the moving three-day average high temperature was associated with more critical violations. In conversations with inspection managers, researchers understood this to be associated with potential mechanical failures---driven by the heat---of equipment that maintained food temperature, a main source of critical violations.

Sanitation code complaints are one of the top complaints registered with the City of Chicago through its 311 system (including web and text reports). Sanitation code complaints include:




```{r table_of_coefficients, echo=FALSE}
knitr::kable(model$beta[,w.lam], digits=2, caption="Table of Coefficients")
```

# Evaluation

After formulating the analytical model, the the principal question for researchers turned to whether this analytical model provides more efficiency for the food inspection team. CDPH operational procedures requires the department to inspect every risk 1 and risk 2 restaurant. Therefore, the operational goal is to allow inspectors to discover critical violations earlier than their current operations.

The researchers applied a protocol to discover whether the analytical model could accelerate the rate of finding critical violations. This objective was slightly different than what the researchers initially sought to find: trying to find an increase in restaurants found with critical violations.

## Evaluation Design

The analytical model was trained on data from January 2011 through January 2014, which results were described in the previous sections. 

[INSERT FIT CODE]

The researchers waited until CDPH completed food inspections in September and October 2014. This timeframe ensured significant time passed between the test period (January 2011 through January 2014) and the evaluation period. It's likely any temporal correlation would subside between the test and evaluation period. CDPH was not aware this timeframe would be used for an evaluation in order to prevent against a Hawthorne Effect or other bias. Again, to reduce any potential to bias within reason, senior management at CDPH was aware of on-going research, but sanitarians were not informed of the research. Finally, several months passed between model development and the evaluation period, reducing a perception of the evaluation period.

The evaluation period lasted two months, from ```r #dat[iiTest, range(Inspection_Date)][1]``` to ```r #dat[iiTest, range(Inspection_Date)][2]``` and calculate the percentage of inspections that result in critical violations in the first half of the inspections during this period. The number of violations found during this period can be considered as status quo or current mode of operation. It serves as a baseline to capture performance levels of sanitarians, namely, the proportion and rate of critical violations that are found.

Meanwhile, we calculate the point predictions for each establishment using the training data from 2011 through 2014. The training data does not include the evaluation period so not to provide additional feedback from the evaluation period. We sort the establishments that were inspected during the evaluation in descending order of predicted values, placing the highest risk restaurants at the top of the list.

We calculate the percentage of those restaurants that would be inspected in the first half if the predictive model was used. The difference between the percentage of establishments found with critical violations during this period reflects the relative gain or loss of efficiency. Finding a greater percentage of critical violations with the predictive model indicates results can be found earlier. A similiar or reduced amount indicates the predictive model provides no benefit or is less efficient, respectively.

Note that this experimental design is assumed to yield the name number of restaurants found with critical violations. Indeed, under the premise that CDPH will inspect all restaurants, researchers will presume the number of violations will remain relatively the same. The objective of the model is to find critical violations earlier throughout the year.

## Results

CDPH completed ```r dat[iiTest, .N]``` inspections between ```r #dat[iiTest, range(Inspection_Date)][1]``` and ```r #dat[iiTest, range(Inspection_Date)][2]```. During this time, CDPH found ```r dat[iiTest, sum(criticalFound)] ``` violations, ```r dat[iiTest, 100*(sum(criticalFound)/.N)]```percent of all inspections. The rate of violations is consistent with the historical average of approximately 15 percent.
```{r prepare_data, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
# ## Subset test period
datTest <- dat[iiTest]

## Identify the ACTUAL first and second periods
datTest[ , period := ifelse(Inspection_Date < median(Inspection_Date), 1, 2)]
datTest[, .N, keyby=list(period)]
## Identify top half of scores (which *would have* been the first period)
datTest[ , period_modeled := ifelse(glm_pred > median(glm_pred), 1, 2)]
datTest[, .N, keyby=list(period_modeled)]

## Total of inspections / critical found for ACTUAL data
datTest[, list(.N, Violations = sum(criticalFound)), keyby=list(period)]

## Total of inspections / critical found for MODELED scenario
datTest[, list(.N, Violations = sum(criticalFound)), keyby=list(period_modeled)]

## Another way to say "how many would you have found  in the first period"
datTest[period == 1, sum(criticalFound)]
datTest[period_modeled == 1, sum(criticalFound)]
```
The research was split in two periods: period 1 representing the first half of work and period 2 representing the latter half. The team could not simply divide violations in half to determine the two periods. Because the original data does not contain a timestamp, only containing the date of inspection, we chose a cutoff which represents the day closest to an even distribution. Even then, ```r summary_of_eval_results_table$"Number of Inspections"[1]``` inspections, ```r 100 * (summary_of_eval_results_table$"Number of Inspections"[1]/(summary_of_eval_results_table$"Number of Inspections"[1] + summary_of_eval_results_table$"Number of Inspections"[2]))``` percent of all inspections, were considered for the first period while ```r summary_of_eval_results_table$"Number of Inspections"[2]``` inspections were included in the second.

Thus, we focus on comparing the percentage of violations found in the first period to the second period.

```{r summary_of_eval_results, echo=FALSE, warning=FALSE}
kable(summary_of_eval_results_table, digits=0, caption="Summary of Findings")
```

Below shows the Gini curve for the modelled inspection period.
```{r}
## show gini performance of inspector model on test data set
dat[iiTest, gini(glm_pred, criticalFound, plot=TRUE)]
```




## Basic model performance

```{r, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
## show gini performance of inspector model on test data set
dat[iiTest, gini(glm_pred, criticalFound, plot=TRUE)]
```

# Summary






## Confustion matrix for one cutoff (.25)

```{r, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
## Calculate confusion matrix values for evaluation
calculate_confusion_values(actual = dat[iiTest, criticalFound],
                           expected = dat[iiTest, glm_pred], 
                           r = .25)
```



```{r, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
geneorama::loadinstall_libraries(c("reshape2", "MASS", "splines"))
##------------------------------------------------------------------------------
## ANALYZE DATA
##------------------------------------------------------------------------------
str(dat)

dat[ , .N, list(Results)]
dat[ , .N, list(Inspection_Type)]

## Annual summary of passes
PassYearly <- dat[ , .N, list(Results = Results, 
                              Year = round(Inspection_Date, "year"))]
PassYearly
dcast.data.table(PassYearly, Year ~ Results, value.var="N")

## Monthly summary of passes
PassMonthly <- dat[i = Inspection_Type == "Canvass" , 
                   j = list(N = as.numeric(.N)), 
                   by = list(Results = Results, 
                             Date = round(Inspection_Date, "month"))]
PassMonthly
dcast.data.table(data = PassMonthly, formula = Date ~ Results,
                 value.var = "N", fill = 0)

##------------------------------------------------------------------------------
## DAILY SUMMARY
##------------------------------------------------------------------------------
canvas_summary <- dat[Inspection_Type == "Canvass" & Results == "Fail",
                      list(N_fail = .N),
                      keyby = Inspection_Date][
                          dat[Inspection_Type == "Canvass",
                              list(N_total=.N),
                              keyby = Inspection_Date]]
setcolorder(canvas_summary, c('Inspection_Date', 'N_total', 'N_fail'))
canvas_summary[ , Pct_fail := N_fail / N_total]
geneorama::convert_datatable_IntNum(canvas_summary)
canvas_summary


ggplot(melt(canvas_summary, id.vars = "Inspection_Date"))+
    aes(Inspection_Date, value, colour=variable) +    
    geom_line() + facet_wrap(~variable, scales="free") + 
    stat_smooth(method = rlm, formula= y ~ ns(x,9), colour="black") +
    stat_smooth(method = lm, formula= y ~ ns(x,9), colour="blue")

##------------------------------------------------------------------------------
## WEEKLY SUMMARY
##------------------------------------------------------------------------------
canvas_summary_w <- dat[i = Inspection_Type == "Canvass" & Results == "Fail",
                        j = list(N_fail=.N),
                        keyby = list(week=geneorama::round_weeks(Inspection_Date))][
                            dat[i = Inspection_Type == "Canvass",
                                j = list(N_total=.N),
                                keyby = list(week=geneorama::round_weeks(Inspection_Date))]]
setcolorder(canvas_summary_w, c('week', 'N_total', 'N_fail'))
canvas_summary_w[,Pct_fail:=N_fail/N_total]
geneorama::convert_datatable_IntNum(canvas_summary_w)
canvas_summary_w
ggplot(melt(canvas_summary_w, id.vars = "week"))+
    aes(week, value, colour=variable) +    
    geom_line() + facet_wrap(~variable, scales="free") + 
    stat_smooth(method = rlm, formula= y ~ ns(x,9), colour="black") +
    stat_smooth(method = lm, formula= y ~ ns(x,9), colour="blue")
canvas_summary_w[,sum(N_total)]

```










